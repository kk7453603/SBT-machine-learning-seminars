{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# plt.style.use('seaborn-colorblind')\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Масштабирование признаков\n",
    "\n",
    "**Определение:** *Масштабирование признаков* - это метод, используемый для стандартизации диапазона независимых переменных или признаков данных. В обработке данных это также известно как нормализация данных и обычно выполняется на этапе предварительной обработки данных.\n",
    "\n",
    "### Зачем важно масштабирование признаков\n",
    "\n",
    "Если диапазон входных данных изменяется, то в некоторых алгоритмах функции потерь не будут работать должным образом.\n",
    "\n",
    "- Градиентный спуск сходится намного быстрее при выполнении масштабирования признаков. Градиентный спуск - это распространенный алгоритм оптимизации, используемый в логистической регрессии, методе опорных векторов (SVM), нейронных сетях и т. д.\n",
    "- Алгоритмы, которые включают вычисление расстояний, такие как k-ближайших соседей (KNN), кластеризация, также зависят от масштаба признаков. Рассмотрите, как вычисляется евклидово расстояние: берется корень квадратный из суммы квадратов различий между наблюдениями. Это расстояние может сильно зависеть от различий в масштабе между переменными. Переменные с большими дисперсиями оказывают большее воздействие на это измерение, чем переменные с маленькими дисперсиями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cols = [\n",
    "    'Pclass', 'Sex', 'Age', 'Fare', 'SibSp',\n",
    "    'Survived'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('./data/titanic.csv', usecols=use_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp     Fare\n",
       "0         0       3    male  22.0      1   7.2500\n",
       "1         1       1  female  38.0      1  71.2833\n",
       "2         1       3  female  26.0      0   7.9250"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623, 4), (268, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[[\"Pclass\", \"Sex\", \"SibSp\", \"Fare\"]], data.Survived, test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация/Стадартизация/Z стандартизация\n",
    "\n",
    "Убираем среднее и мастабируем на стандартное отклонение\n",
    "\n",
    "<br />z = (X - X.mean) /  std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex  SibSp     Fare  Fare_zscore\n",
      "857       1    male      0  26.5500    -0.122530\n",
      "52        1  female      1  76.7292     0.918124\n",
      "386       3    male      5  46.9000     0.299503\n",
      "124       1    male      0  77.2875     0.929702\n",
      "578       3  female      1  14.4583    -0.373297\n",
      "549       2    male      1  36.7500     0.089005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler().fit(X_train[['Fare']])\n",
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Fare_zscore'] = ss.transform(X_train_copy[['Fare']])\n",
    "print(X_train_copy.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.916437306188636e-17\n",
      "1.0008035356861\n"
     ]
    }
   ],
   "source": [
    "# проверка что mean=0 и std=1\n",
    "print(X_train_copy['Fare_zscore'].mean())\n",
    "print(X_train_copy['Fare_zscore'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max scaling\n",
    "Мастштабировиение по min/max\n",
    "\n",
    "\n",
    "К [0,1]  <br />X_scaled = (X - X.min / (X.max - X.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex  SibSp     Fare  Fare_minmax\n",
      "857       1    male      0  26.5500     0.051822\n",
      "52        1  female      1  76.7292     0.149765\n",
      "386       3    male      5  46.9000     0.091543\n",
      "124       1    male      0  77.2875     0.150855\n",
      "578       3  female      1  14.4583     0.028221\n",
      "549       2    male      1  36.7500     0.071731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler().fit(X_train[['Fare']])\n",
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Fare_minmax'] = mms.transform(X_train_copy[['Fare']])\n",
    "print(X_train_copy.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Проверим что min = 0, max = 1\n",
    "print(X_train_copy['Fare_minmax'].max())\n",
    "print(X_train_copy['Fare_minmax'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust scaling\n",
    "Убираем медиану и мастабирование с Interquartile Ranges Rule\n",
    "\n",
    "<br />X_scaled = (X - X.median) / IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex  SibSp     Fare  Fare_robust\n",
      "857       1    male      0  26.5500     0.492275\n",
      "52        1  female      1  76.7292     2.630973\n",
      "386       3    male      5  46.9000     1.359616\n",
      "124       1    male      0  77.2875     2.654768\n",
      "578       3  female      1  14.4583    -0.023088\n",
      "549       2    male      1  36.7500     0.927011\n"
     ]
    }
   ],
   "source": [
    "# add the new created feature\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler().fit(X_train[['Fare']])\n",
    "X_train_copy = X_train.copy(deep=True)\n",
    "X_train_copy['Fare_robust'] = rs.transform(X_train_copy[['Fare']])\n",
    "print(X_train_copy.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.196769312733085\n",
      "-0.6393180607352158\n"
     ]
    }
   ],
   "source": [
    "# check the range of Fare_minmax\n",
    "print(X_train_copy['Fare_robust'].max())\n",
    "print(X_train_copy['Fare_robust'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если ваш признак не имеет нормальное распределение, например, имеет скошенное распределение или содержит выбросы, то нормализация и стандартизация не являются хорошими выборами, так как они сжимают большинство данных в узкий диапазон.\n",
    "\n",
    "- Тем не менее, мы можем преобразовать признак в нормально распределенный и затем использовать нормализацию и стандартизацию. \n",
    "- При вычислении расстояний или ковариации (алгоритмы, такие как кластеризация, PCA и LDA), лучше использовать нормализацию и стандартизацию, так как это устраняет влияние масштабов на дисперсию и ковариацию. Объяснение можно найти [здесь](ссылка).\n",
    "\n",
    "Масштабирование Min-Max имеет те же недостатки, что и нормализация и стандартизация, и новые данные могут не ограничиваться в диапазоне [0,1], так как они могут выходить за исходный диапазон. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
